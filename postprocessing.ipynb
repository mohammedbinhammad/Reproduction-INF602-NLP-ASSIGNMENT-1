{
 "metadata": {
  "name": "",
  "signature": "sha256:e3c7f2e6c29fc1a23c37497c4abe14168c70242c1c271d0ab3603dd02bf762c6"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "POST PROCESSING FROM THE CLASSIFIER"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Now inpect the \"returns\" variable from Dispatcher.py\n",
      "import pickle\n",
      "returns = pickle.load(open('returns.pickle', 'rb'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import Counter, OrderedDict\n",
      "all_words = Counter()\n",
      "for n in range(len(returns)):\n",
      "    (sub_query_npos, sub_words, sub_word_weights, sub_stair_horizontal_line, sub_stair_news) = returns[n]\n",
      "    for word in sub_words.keys():\n",
      "        all_words[word] += 1\n",
      "used_words = set()\n",
      "MAX_USED_WORDS = 30\n",
      "for item in all_words.most_common(MAX_USED_WORDS):\n",
      "    used_words.add(item[0])\n",
      "print(\"USED WORDS::\", used_words)        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('USED WORDS::', set([u'kernel', u'regret', u'energy', u'rank', u'cost', u'dual', u'convex', u'matching', u'clustering', u'matrix', u'gradient', u'graph', u'submodular', u'objective', u'optimal', u'norm', u'function', u'ranking', u'linear', u'max', u'policy', u'loss', u'svm', u'algorithm', u'solution', u'mlp', u'sparse', u'problem', u'margin', u'constraints']))\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "CLASSIFICATION PHASE"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import glob\n",
      "# Year 2010\n",
      "bins = glob.glob(\"/Users/maxlam/.ai/databases/nips/y_1262304000_1293839999_content.npz\")\n",
      "from anser_indicus.preprocessing.sparse_matrix import SparseMatrix\n",
      "from anser_indicus.data.database_pool import DatabasePool\n",
      "mat = SparseMatrix()\n",
      "pool = DatabasePool()\n",
      "mat.attach_database('nips',pool=pool)\n",
      "mat.load_from_binary(bins[0],pool=pool)\n",
      "print \"DONE\"\n",
      "ndocs = mat.mat.shape[0]\n",
      "nwords = mat.mat.shape[1]\n",
      "print \"Total # documents = \", ndocs\n",
      "print \"Total # words = \", nwords\n",
      "#############\n",
      "# Compute the binary vector y, each component in {0, 1}\n",
      "#############\n",
      "y = [1 for i in range(int(ndocs))]\n",
      "pos = {'search_by': u'both', 'all': [u'optimization']}\n",
      "print \"pos:\",pos\n",
      "if 'all' in pos:\n",
      "    for term in pos['all']:\n",
      "        print(term)\n",
      "        print(mat.lookup_termids([term]))\n",
      "        col = mat.lookup_termids([term])[0]\n",
      "        if col >= 0 :\n",
      "            print \"query =\", term, \", column =\",col\n",
      "            for i in range(len(y)):\n",
      "                if mat.mat[i, col] == 0:\n",
      "                    y[i] = 0\n",
      "print \"Set up positive class\"\n",
      "print(y)\n",
      "npos = sum(y)\n",
      "sub_query_npos = npos * 1.0 / max(1, ndocs)\n",
      "print \"Total # positive documents = \", npos\n",
      "print(mat.mat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "attaching database nips\n",
        "Looking for /Users/maxlam/.ai/databases/nips/y_1262304000_1293839999_content.npz\n",
        "split binname: /Users/maxlam/.ai/databases/nips/y_1262304000_1293839999_content\n",
        "OPENED\n",
        "LOADED"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "CREATED MAT"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "DONE"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Total # documents =  292\n",
        "Total # words =  29115\n",
        "pos: {'search_by': u'both', 'all': [u'optimization']}\n",
        "optimization\n",
        "select distinct termid from n1 where term == ?; optimization\n",
        "[533]\n",
        "select distinct termid from n1 where term == ?; optimization\n",
        "query = optimization , column = 533\n",
        "Set up positive class\n",
        "[1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1]\n",
        "Total # positive documents =  197\n",
        "  (0, 0)\t1.0\n",
        "  (2, 0)\t1.0\n",
        "  (12, 0)\t3.0\n",
        "  (13, 0)\t1.0\n",
        "  (26, 0)\t1.0\n",
        "  (44, 0)\t1.0\n",
        "  (50, 0)\t4.0\n",
        "  (52, 0)\t2.0\n",
        "  (53, 0)\t3.0\n",
        "  (54, 0)\t3.0\n",
        "  (56, 0)\t2.0\n",
        "  (57, 0)\t5.0\n",
        "  (60, 0)\t3.0\n",
        "  (73, 0)\t1.0\n",
        "  (74, 0)\t2.0\n",
        "  (81, 0)\t2.0\n",
        "  (97, 0)\t2.0\n",
        "  (109, 0)\t1.0\n",
        "  (115, 0)\t1.0\n",
        "  (141, 0)\t37.0\n",
        "  (146, 0)\t1.0\n",
        "  (147, 0)\t6.0\n",
        "  (153, 0)\t1.0\n",
        "  (154, 0)\t1.0\n",
        "  (163, 0)\t1.0\n",
        "  :\t:\n",
        "  (291, 29090)\t1.0\n",
        "  (291, 29091)\t1.0\n",
        "  (291, 29092)\t1.0\n",
        "  (291, 29093)\t2.0\n",
        "  (291, 29094)\t1.0\n",
        "  (291, 29095)\t1.0\n",
        "  (291, 29096)\t1.0\n",
        "  (291, 29097)\t2.0\n",
        "  (291, 29098)\t1.0\n",
        "  (291, 29099)\t1.0\n",
        "  (291, 29100)\t1.0\n",
        "  (291, 29101)\t1.0\n",
        "  (291, 29102)\t1.0\n",
        "  (291, 29103)\t3.0\n",
        "  (291, 29104)\t1.0\n",
        "  (291, 29105)\t1.0\n",
        "  (291, 29106)\t1.0\n",
        "  (291, 29107)\t1.0\n",
        "  (291, 29108)\t1.0\n",
        "  (291, 29109)\t2.0\n",
        "  (291, 29110)\t1.0\n",
        "  (291, 29111)\t1.0\n",
        "  (291, 29112)\t1.0\n",
        "  (291, 29113)\t20.0\n",
        "  (291, 29114)\t1.0\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = mat.mat\n",
      "from sklearn.feature_extraction.text import TfidfTransformer\n",
      "tfidf_transformer = TfidfTransformer(norm='l2')\n",
      "X_tf = tfidf_transformer.fit_transform(X)\n",
      "from sklearn.linear_model import SGDClassifier\n",
      "ml = SGDClassifier(loss='log', penalty='l2', alpha = 0.001, l1_ratio = 0.9,  n_iter = 10)\n",
      "ml.fit(X_tf, y)\n",
      "v = ml.coef_[0]\n",
      "print(X_tf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  (0, 801)\t0.00808294290419\n",
        "  (0, 800)\t0.00492358169049\n",
        "  (0, 799)\t0.00954354498901\n",
        "  (0, 798)\t0.00468865967815\n",
        "  (0, 797)\t0.00954354498901\n",
        "  (0, 796)\t0.0064416906084\n",
        "  (0, 795)\t0.00889721827018\n",
        "  (0, 794)\t0.112949418917\n",
        "  (0, 793)\t0.0140061060232\n",
        "  (0, 792)\t0.00954354498901\n",
        "  (0, 791)\t0.00197994370187\n",
        "  (0, 790)\t0.0437214610655\n",
        "  (0, 789)\t0.00917208730195\n",
        "  (0, 788)\t0.00401903087033\n",
        "  (0, 787)\t0.00779231544644\n",
        "  (0, 786)\t0.0115068062918\n",
        "  (0, 785)\t0.00558250979897\n",
        "  (0, 784)\t0.00754659343213\n",
        "  (0, 783)\t0.0268656418514\n",
        "  (0, 782)\t0.00697804008045\n",
        "  (0, 781)\t0.00444473905152\n",
        "  (0, 780)\t0.012869569084\n",
        "  (0, 779)\t0.0105117265629\n",
        "  (0, 778)\t0.00909103259077\n",
        "  (0, 777)\t0.0039049192205\n",
        "  :\t:\n",
        "  (291, 100)\t0.0281131350354\n",
        "  (291, 94)\t0.00479048126216\n",
        "  (291, 93)\t0.0296524063774\n",
        "  (291, 77)\t0.0153448647618\n",
        "  (291, 75)\t0.00893124679593\n",
        "  (291, 72)\t0.00804383025908\n",
        "  (291, 71)\t0.0432311584963\n",
        "  (291, 64)\t0.0760465002103\n",
        "  (291, 62)\t0.00551801556119\n",
        "  (291, 60)\t0.0216706399614\n",
        "  (291, 58)\t0.0119354838461\n",
        "  (291, 55)\t0.013314016235\n",
        "  (291, 53)\t0.0215667073488\n",
        "  (291, 52)\t0.018788985608\n",
        "  (291, 46)\t0.0101805998037\n",
        "  (291, 41)\t0.0392202425664\n",
        "  (291, 40)\t0.00655688596099\n",
        "  (291, 33)\t0.0121894172657\n",
        "  (291, 29)\t0.00651268379729\n",
        "  (291, 25)\t0.00295288334469\n",
        "  (291, 21)\t0.00335337926606\n",
        "  (291, 18)\t0.0120727784985\n",
        "  (291, 12)\t0.00630288475984\n",
        "  (291, 9)\t0.0108637857443\n",
        "  (291, 7)\t0.00433599266849\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "u = sorted(range(nwords), key = lambda k: v[k], reverse=True)\n",
      "max_v = float(v[u[0]])\n",
      "MAX_WORDS = 20 # set to 50 if the number of time ranges is <= 10\n",
      "i = 0\n",
      "j = 0\n",
      "while i < len(u) and j < MAX_WORDS:\n",
      "    #begin = time()\n",
      "    if v[u[i]]/max_v < 1E-9: #hard-threshold relatively very low scores\n",
      "        i += 1\n",
      "        continue\n",
      "    i += 1\n",
      "    word = mat.lookup_terms([u[i]])[0]\n",
      "    if (len(word) <= 1) or (not word.isalpha()): #if word is a stopword, or word has non-alphabetic letters\n",
      "        continue\n",
      "    \n",
      "    query = 'optimization'\n",
      "    word_is_query_term = (word == query) #ignore predictors that are the query term\n",
      "    if word_is_query_term:\n",
      "        continue\n",
      "    \n",
      "    # now select this word\n",
      "    word_weight = 100.0 * v[u[i]]/max_v\n",
      "    j += 1\n",
      "    print word, word_weight"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "problem 74.8707311812\n",
        "convex 70.3989282554\n",
        "lasso 61.4024390685\n",
        "objective 58.4948309534\n",
        "group 52.7004192008\n",
        "cascade 52.6984018099\n",
        "max 50.1744237423\n",
        "graph 48.8041576532\n",
        "regularization 47.7422403449\n",
        "function 44.2711912557\n",
        "loss 44.0770865679\n",
        "submodular 43.8542902954\n",
        "coding 43.307865391\n",
        "rank 43.0872129245\n",
        "optimal 41.9785715805\n",
        "constraints 41.9280158363\n",
        "image 40.8316264491\n",
        "sparse 40.6805560753\n",
        "norm 40.3747446463\n",
        "solution 39.176577251\n"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Output from Statnews Dispatcher\n",
      "('SUB WORDS', {u'function': [(1262304000, 1293839999, 44.271191255713632)], u'loss': [(1262304000, 1293839999, 44.077086567850017)], u'regularization': [(1262304000, 1293839999, 47.742240344940434)], u'group': [(1262304000, 1293839999, 52.700419200806557)], u'max': [(1262304000, 1293839999, 50.174423742252131)], u'image': [(1262304000, 1293839999, 40.831626449074925)], u'coding': [(1262304000, 1293839999, 43.307865390951449)], u'solution': [(1262304000, 1293839999, 39.176577251046872)], u'rank': [(1262304000, 1293839999, 43.087212924498139)], u'cascade': [(1262304000, 1293839999, 52.698401809862325)], u'submodular': [(1262304000, 1293839999, 43.854290295383002)], u'graph': [(1262304000, 1293839999, 48.804157653174194)], u'sparse': [(1262304000, 1293839999, 40.680556075302349)], u'convex': [(1262304000, 1293839999, 70.398928255420969)], u'objective': [(1262304000, 1293839999, 58.494830953444733)], u'optimal': [(1262304000, 1293839999, 41.978571580489259)], u'problem': [(1262304000, 1293839999, 74.870731181181512)], u'constraints': [(1262304000, 1293839999, 41.928015836297305)], u'norm': [(1262304000, 1293839999, 40.374744646258918)], u'lasso': [(1262304000, 1293839999, 61.4024390685451)]})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 70,
       "text": [
        "('SUB WORDS',\n",
        " {u'cascade': [(1262304000, 1293839999, 52.698401809862325)],\n",
        "  u'coding': [(1262304000, 1293839999, 43.30786539095145)],\n",
        "  u'constraints': [(1262304000, 1293839999, 41.928015836297305)],\n",
        "  u'convex': [(1262304000, 1293839999, 70.39892825542097)],\n",
        "  u'function': [(1262304000, 1293839999, 44.27119125571363)],\n",
        "  u'graph': [(1262304000, 1293839999, 48.804157653174194)],\n",
        "  u'group': [(1262304000, 1293839999, 52.70041920080656)],\n",
        "  u'image': [(1262304000, 1293839999, 40.831626449074925)],\n",
        "  u'lasso': [(1262304000, 1293839999, 61.4024390685451)],\n",
        "  u'loss': [(1262304000, 1293839999, 44.07708656785002)],\n",
        "  u'max': [(1262304000, 1293839999, 50.17442374225213)],\n",
        "  u'norm': [(1262304000, 1293839999, 40.37474464625892)],\n",
        "  u'objective': [(1262304000, 1293839999, 58.49483095344473)],\n",
        "  u'optimal': [(1262304000, 1293839999, 41.97857158048926)],\n",
        "  u'problem': [(1262304000, 1293839999, 74.87073118118151)],\n",
        "  u'rank': [(1262304000, 1293839999, 43.08721292449814)],\n",
        "  u'regularization': [(1262304000, 1293839999, 47.742240344940434)],\n",
        "  u'solution': [(1262304000, 1293839999, 39.17657725104687)],\n",
        "  u'sparse': [(1262304000, 1293839999, 40.68055607530235)],\n",
        "  u'submodular': [(1262304000, 1293839999, 43.854290295383)]})"
       ]
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "QUERY: OPTIMIZATION - current output from Statnews Dispatcher"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Current statnews dispatcher:\n",
      "from IPython.core.display import HTML\n",
      "HTML('<iframe src=http://statnews.eecs.berkeley.edu/queries/10_1411754434 width = 900 height = 700>')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<iframe src=http://statnews.eecs.berkeley.edu/queries/10_1411754434 width = 900 height = 700>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 73,
       "text": [
        "<IPython.core.display.HTML at 0x12285f510>"
       ]
      }
     ],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1] ==[1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}